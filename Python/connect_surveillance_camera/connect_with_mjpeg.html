<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="木下英俊">
  <meta name="description" content="木下英俊が自身のためにプログラムメモを残すことを目的に作成したページです。">
  <meta name="keywords" content="">
  <!-- キャッシュ無効化 -->
  <meta http-equiv="Cache-Control" content="no-cache">
	
  <title>MJPEGで画像を取得する</title>
	
  <!-- CSS -->
  <link href="https://unpkg.com/ress/dist/ress.min.css" rel="stylesheet">
	<link rel="stylesheet" href="../../design.css" type="text/css">
  
	<!-- Start for 'google-code-prettify' -->
	<link href="../../prettify/styles/desert.css" rel="stylesheet" type="text/css">
	<script src="../../prettify/prettify.js" type="text/javascript"></script>
	<!-- End for 'google-code-prettify' -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2DZQK54C2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-V2DZQK54C2');
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  
  <style type="text/css">
  .auto-style2 {
    background-color: #484800;
  }
  .super {
    vertical-align: super;
  }
  </style>

</head>

<body onload="prettyPrint();">

<h1>MJPEG で画像を取得する</h1>

<p> i-PRO の監視カメラ i-PRO mini (WV-S7130W) を入手したので、MJPEG で映像取得して遊んでみます。</p>
<p> &nbsp;</p>
<table style="border: 1px solid #808080; width: 800px; max-width:100%; background-color: #F0F0F0;">
  <tr>
    <td>
      <nav>
        <h2> 目次</h2>
        <p>
        <a href="#1._MJPEG 表記仕様">1. MJPEG 表記仕様</a><br>
        <a href="#2._Python_で_i-PRO_mini_(WV-S7130W)_と接続して映像を表示してみる">2. Python で i-PRO mini (WV-S7130W) と接続して映像を表示してみる</a><br>
        <a href="#3.プログラムを改善する_">3. プログラムを改善する</a><br>
        <a href="#4. OpenCV で顔認識を加えてみる">4. OpenCV で顔認識を加えてみる</a><br>
        <a href="#4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a><br>
        <a href="#4-2._顔認識部分を別プロセスの処理にしてみる">4-2. 顔認識部分を別プロセスの処理にしてみる</a><br>
        <br>
        <a href="#ライセンス">ライセンス</a><br>
        <a href="#参考">参考</a><br>
        </p>
      </nav>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p> 製品紹介ページ： </p>
<ul>
  <li><a href="https://cwc.i-pro.com/pages/i-pro-mini-lp" target="_blank">
  i-pro-mini-lp</a></li>
  <li>
  <a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130wux" target="_blank">
  i-PRO mini 無線LANモデル WV-S7130WUX</a></li>
</ul>
<p> &nbsp;</p>
<p> <img alt="" src="connect_with_rtsp/img10.jpg"></p>

<p>&nbsp;</p>
<p>&nbsp;</p>

<section>
	<h2> <a name="1._MJPEG 表記仕様">1. MJPEG 表記仕様</a></h2>
	<h4>[概要]</h4>
  	<p> MJPEG で接続するための表記を以下に記載します。</p>
    <p> 「ネットワークカメラCGIコマンドインターフェース仕様書 統合版」<span class="super">[1]</span> で下記に記載されている情報を元に加筆などしています。</p>
    <ul>
      <li>「3.13 動画像取得(Motion JPEG 形式取得：リアルタイム) (nphMotionJpeg)」</li>
    </ul>
    <p>&nbsp;</p>
    <p><span class="cpp-source">http://&lt;user-id&gt;:&lt;user-password&gt;@&lt;カメラのIPアドレス&gt;/nphMotionJpeg?Resolution=&lt;解像度&gt;&amp;Quality=&lt;品質&gt;&amp;Framerate=&lt;フレームレート&gt;</span></p>
    <p>&nbsp;</p>
    <p>(例) <span class="cpp-source">
    <a href="mailto:rtsp://admin:password@192.168.0.10/MediaInput/stream_1">http://admin:password@192.168.0.10/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15</a></span></p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h3>注意事項</h3>
    <ul>
      <li>実験してみたところ、ストリーム(1)～(4) を On にしているとMJPEGの配信性能が落ちる様子です。フレームレートを例えば 15 
      と設定してもコマ落ちが多く発生しているように見えました。<br>カメラの設定にて、ストリーム(1)～(4)を Off、にすることで 30fps 
      の動作もできているように見えます。</li>
      <li>CGI のせっていでは "Framerate" の指定を必ず行った方が良さそうです。試しに Framerate 指定を行わなかったところ 0.2fps 
    程度の表示となりました。恐らくデフォルト値が 0.2fps ぐらいになっていると思われます。</li>
    </ul>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
</section>
<p>&nbsp;</p>

<section>
	<h2> <a name="2._Python_で_i-PRO_mini_(WV-S7130W)_と接続して映像を表示してみる">2. Python で i-PRO mini (WV-S7130W) と接続して映像を表示してみる</a></h2>
	<h4>[概要]</h4>
    <p>とりあえず映像を取得してPC画面に表示するまでをやってみます。</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.2 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
    <p>&nbsp;</p>
    <h3>2-1. １つ目の方法</h3>
    <p>まずは簡単な方法から。RTSP のコードとほとんど同じ内容で実現できました。</p>
    <p>&nbsp;</p>
    <h4>[プログラム]</h4>
  <p>[プログラムソース &quot;connect_with_mjpeg_1_1.py&quot;]</p>
  
	<pre class="prettyprint linenums lang-py">
'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる 
[library install]
 &nbsp; &nbsp;pip install opencv-python 
'''

import cv2
user_id = "user-id"     # ご使用のカメラ設定に合わせて変更
user_pw = "password"    # ご使用のカメラ設定に合わせて変更
host = "192.168.0.10"   # ご使用のカメラ設定に合わせて変更
cap = cv2.VideoCapture(f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15")

while(True):
    try:
        ret, frame = cap.read()
        if ret == True:
            # 使っているPC画面に適当に収まる表示大きさへリサイズ
            frame2 = cv2.resize(frame, (1280, 760))
            cv2.imshow('VIDEO', frame2)

        # コンソール上で ctrl-c を押すとプログラムを終了する。
        # GUI 上で ctrl-c してもプログラムを終了できない。
        cv2.waitKey(1)    # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！

    except KeyboardInterrupt:
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>

    <p>&nbsp;</p>
    <p>上記プログラムを動かしてみます。実行はこんな感じで行います。</p>
    <p><span class="cpp-source"><strong>python</strong> connect_with_mjpeg_1_1.py</span></p>
    <p>&nbsp;</p>
    <p>Windows環境で複数の Python バージョンをインストールしている場合、下図のような感じで実行バージョンを指定することもできます。<br>
    こちらはバージョン 3.10 の Python で実行を指示する例です。</p>
    <p><span class="cpp-source"><strong>py</strong> -3.10 connect_with_mjpeg_1_1.py</span></p>
    <p>&nbsp;</p>
    <p>上記プログラムを動かした様子を動画で示します。</p>
    <p>こんなに簡単なプログラムでとても快適な映像表示を実現することができました。</p>
    <p>[注意] 上記でも記載しましたが、カメラ側の設定でストリーム(1)～(4)を Off にすることで滑らかな映像表示を実現できました。On 
    のままでもプログラム自体は動作しますが、5fps 程度の映像となりました。</p>
    
<video controls autoplay="y" loop="y" src="connect_with_mjpeg/mjpeg_first.mp4" width="800px">
  <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
</video>

<p>[動画] MJPEG でカメラと接続して映像表示してみた様子</p>
    
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h3>2-2. 他の方法</h3>
    <p>下記のような別の方法でも MJPEG の読出しをできるみたいです。参考記事[2]を参考に作成してみました。</p>
    <p>&nbsp;</p>
    <h4>[プログラム]</h4>
  <p>[プログラムソース &quot;connect_with_mjpeg_1_2.py&quot;]</p>
  
	  <pre class="prettyprint linenums lang-py">
'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみます。
    このプログラムでは MJPEG(Motion JPEG) 形式で接続してみます。

[library install]
    pip install opencv-python
'''

import cv2
import urllib.request as rq
import numpy as np


user_id = "user-id"     # ご使用のカメラ設定に合わせて変更
user_pw = "password"    # ご使用のカメラ設定に合わせて変更
host = "192.168.0.10"   # ご使用のカメラ設定に合わせて変更
winname = "VIDEO"       # ウィンドウタイトル

url = f"http://{host}/cgi-bin/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15"


'''
[abstract]
    IP カメラと認証処理を行います。

[params]
    uri:      mjpeg 開始 CGI コマンド
    user:     IPカメラの user-id
    passwd:   IPカメラの user-password
'''
def set_digest_auth(uri, user, passwd):
    pass_mgr = rq.HTTPPasswordMgrWithDefaultRealm()
    pass_mgr.add_password(realm=None, uri=uri, user=user, passwd=passwd)
    auth_handler = rq.HTTPDigestAuthHandler(pass_mgr)
    opener = rq.build_opener(auth_handler)
    rq.install_opener(opener)


set_digest_auth(url, user_id, user_pw)
stream = rq.urlopen(url)

bytes = bytes()
while True:
    bytes += stream.read(1024)
    a = bytes.find(b'\xff\xd8')
    b = bytes.find(b'\xff\xd9')
    if a != -1 and b != -1:
        jpg = bytes[a:b+2]
        bytes = bytes[b+2:]
        frame = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)

        frame2 = cv2.resize(frame, (1280, 760))
        cv2.imshow(winname, frame2)

        if cv2.waitKey(1) &amp; 0xFF == ord('z'):
            break 

cv2.destroyAllWindows()	</pre>
    <p></p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    
</section>

<section>
  <h2><a name="3.プログラムを改善する_">3.プログラムを改善する </a></h2>
	<h4>[概要]</h4>
  <p>前章で作成したプログラムはとても簡単に作成できましたが、いろいろと課題がありました。<br>とりあえず下記３つの課題を解決してみます。</p>
  <p>&nbsp;</p>
  <p>課題１<br>プログラムを起動するたびにウィンドウ位置が変わる。場合によっては画面外へ表示する場合もあって不便。<br>
  適当に画面内に収まる場所に表示してほしい。<br>⇨ 指定する場所にウィンドウを表示するようにします。</p>
  <p>&nbsp;</p>
  <p>課題２<br>プログラムを終了するのが大変。<br>ウィンドウ右上の×を押すとウィンドウがいったん消えるが、すぐに再表示されて終われない。<br>⇨ 
  ウィンドウ右上の✕ボタンでプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
  <p>課題３<br>同様に、任意のキー入力でプログラムを終了できるとうれしい。<br>⇨ "z" キー押下でプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.2 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
  <p>&nbsp;</p>
  
  <p>[プログラムソース &quot;connect_with_mjpeg_2.py&quot;]</p>
	<pre class="prettyprint linenums lang-py">
'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる

[library install]
    pip install opencv-python
'''

import cv2

user_id = "user-id"     # ご使用のカメラ設定に合わせて変更
user_pw = "password"    # ご使用のカメラ設定に合わせて変更
host = "192.168.0.10"   # ご使用のカメラ設定に合わせて変更
winname = "VIDEO"

cap = cv2.VideoCapture(f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15")

<span class="auto-style2">#</span>
<span class="auto-style2">windowInitialized = False</span>

<span class="auto-style2"># Exception 定義</span>
<span class="auto-style2">BackendError = type('BackendError', (Exception,), {})</span>

<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    対象ウィンドウが存在するかを確認する。</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    winname :       ウィンドウタイトル</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    True :          対象ウィンドウは存在する</span>
<span class="auto-style2">    False :         対象ウィンドウは存在しない</span>
<span class="auto-style2">[Exception]</span>
<span class="auto-style2">    BackendError :  バックエンドで使用している Qt でエラー発生</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def IsWindowVisible(winname):</span>
<span class="auto-style2">    try:</span>
<span class="auto-style2">        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)</span>
<span class="auto-style2">        if ret == -1:</span>
<span class="auto-style2">            raise BackendError('Use Qt as backend to check whether window is visible or not.')</span>

<span class="auto-style2">        return bool(ret)</span>

<span class="auto-style2">    except cv2.error:</span>
<span class="auto-style2">        return False</span>


while(True):
    try:
        ret, frame = cap.read()
        if ret == True:
            frame2 = cv2.resize(frame, (1280, 760))
            cv2.imshow(winname, frame2)

<span class="auto-style2">            if windowInitialized==False:</span>
<span class="auto-style2">                # ウィンドウ表示位置が安定しないので、最初の起動時のみ表示場所を指定</span>
<span class="auto-style2">                cv2.moveWindow(winname, 100, 100)</span>
<span class="auto-style2">                windowInitialized = True</span>

<span class="auto-style2">        # "z" キーを押されていたら終了</span>
<span class="auto-style2">        k = cv2.waitKey(1)    # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！</span>
<span class="auto-style2">        if k == ord("z"):</span>
<span class="auto-style2">            break</span>
<span class="auto-style2">        </span>
<span class="auto-style2">        # 指定ウィンドウが無かったら終了</span>
<span class="auto-style2">        if not IsWindowVisible(winname):</span>
<span class="auto-style2">            break</span>

    except KeyboardInterrupt:
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
  <h2><a name="4. OpenCV で顔認識を加えてみる">4. OpenCV で顔認識を加えてみる</a></h2>
  <p>MJPEG の実装でも OpenCV による顔認識を実装してみます。</p>
  <p>MJPEG 接続では映像情報は受け身です。このため高解像度、高フレームレートの映像を処理したとき、OpenCV の処理が追いつくかが心配な部分です。</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.2 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
  <p>&nbsp;</p>
  <h3><a name="4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a></h3>
  <p>とにかくまずはやってみます。</p>
  <p>映像を受信するたびの OpenCV で毎回認識処理を行ってみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;connect_with_mjpeg_3_1.py&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる。
    ここでは opencv を使って顔認識を追加してみます。

[library install]
    pip install opencv-python
'''

import cv2

user_id = "user-id"     # ご使用のカメラ設定に合わせて変更
user_pw = "password"    # ご使用のカメラ設定に合わせて変更
host = "192.168.0.10"   # ご使用のカメラ設定に合わせて変更
winname = "VIDEO"

# Exception 定義
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       ウィンドウタイトル
[Return]
    True :          対象ウィンドウは存在する
    False :         対象ウィンドウは存在しない
[Exception]
    BackendError :  バックエンドで使用している Qt でエラー発生
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False

<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    顔認識して認識結果を返す</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    cascade :       OpenCV の CascadeClassifierオブジェクト</span>
<span class="auto-style2">    image :         OpenCV 形式の画像</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    認識結果</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def DetectFaces(cascade, image):</span>
<span class="auto-style2">    # 顔検出のためにグレイスケール画像に変換</span>
<span class="auto-style2">    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>

<span class="auto-style2">    # 顔を画像から検出 </span>
<span class="auto-style2">    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))</span>

<span class="auto-style2">    # 検出結果を返す</span>
<span class="auto-style2">    return face_list</span>


<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    検出された顔枠情報リストを使って、image 上に赤枠を描画する。</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    image :         OpenCV 形式の画像</span>
<span class="auto-style2">    face_list :     検出された顔枠情報リスト</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    無し</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def DrawFaceRectangles(image, face_list):</span>
<span class="auto-style2">    # 検出した顔の数だけ赤枠を描画</span>
<span class="auto-style2">    if len(face_list) != 0:</span>
<span class="auto-style2">        for (pos_x, pos_y, w, h) in face_list:</span>
<span class="auto-style2">            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")</span>
<span class="auto-style2">            cv2.rectangle(image, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)</span>


'''
[Abstract]
    main 関数
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15") 

    #
    windowInitialized = False

<span class="auto-style2">    # 顔を識別するためのファイル</span>
<span class="auto-style2">    cascade_file = "haarcascade_frontalface_alt2.xml"       # 顔</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye.xml"                   # 目？</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # 目？</span>
<span class="auto-style2">    cascade = cv2.CascadeClassifier(cascade_file)</span>

    while(True):
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # 顔認識</span>
<span class="auto-style2">                face_list = DetectFaces(cascade, frame)</span>

<span class="auto-style2">                # 検出した顔枠を描画</span>
<span class="auto-style2">                DrawFaceRectangles(frame, face_list)</span>

                # PC画面サイズに合わせて適当にリサイズ後、表示
                frame2 = cv2.resize(frame, (1280, 760))
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # ウィンドウ表示位置が安定しないので、最初の起動時のみ表示場所を指定
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # "z" キーを押されていたら終了
            k = cv2.waitKey(1)      # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！
            if k == ord("z"):
                break
            
            # 指定ウィンドウが無かったら終了
            if not IsWindowVisible(winname):
                break


        except KeyboardInterrupt:
            print("KeyboardInterrupt")
            break

    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>結果：</p>
  <p>私のゲーミングPCではこれでもそこそこ動作しました。思ったより動く、という感想です。</p>
  <p>が、それでもだんだん映像が遅れていきます。<br>顔認識処理と描画の部分をコメントアウトすると、映像表示の遅れはなくなります。<br>
  やはり顔認識処理は PC にとって結構重たい処理のようです。</p>
  <p>ちょっと残念。何か改善策を考えてみたいところです。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="4-2._顔認識部分を別プロセスの処理にしてみる">4-2. 顔認識部分を別プロセスの処理にしてみる</a></h3>
  <p>
  そこで、顔認識部分を別タスクに分離することで、映像受信と映像デコード処理を止めずにできるだけ顔認識をやってみる、という感じにプログラムを修正してみます。</p>
  <p>別タスクというと一般的なプログラムでは "スレッド" というテクニックを使いますが、どうやら CPython 
  と呼ばれるプラットフォームの場合はスレッドは複数の処理を同時に実行してくれないらしいです。そこで、ここでは別プロセスを起動し、キューと呼ばれるIOで情報をやり取りしてみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;connect_with_mjpeg_3_2.py&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる。
    ここでは opencv を使って顔認識を追加してみます。

[library install]
    pip install opencv-python
'''

import cv2
<span class="auto-style2">import multiprocessing as mp</span>
<span class="auto-style2">from queue import Empty</span>


user_id = "user-id"     # ご使用のカメラ設定に合わせて変更
user_pw = "password"    # ご使用のカメラ設定に合わせて変更
host = "192.168.0.10"   # ご使用のカメラ設定に合わせて変更
winname = "VIDEO"

<span class="auto-style2"># 顔を識別するためのファイル</span>
<span class="auto-style2">cascade_file = "haarcascade_frontalface_alt2.xml"       # 顔</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye.xml"                   # 目？</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # 目？</span>
<span class="auto-style2">cascade = cv2.CascadeClassifier(cascade_file)</span>


# Exception 定義
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       ウィンドウタイトル
[Return]
    True :          対象ウィンドウは存在する
    False :         対象ウィンドウは存在しない
[Exception]
    BackendError :  バックエンドで使用している Qt でエラー発生
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


'''
[Abstract]
    顔認識して認識結果を返す
[Param]
    cascade :       OpenCV の CascadeClassifierオブジェクト
    image :         OpenCV 形式の画像
[Return]
    検出結果
'''
def DetectFaces(cascade, image):
    # 顔検出のためにグレイスケール画像に変換
    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # 検出した顔の位置情報を取得
    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))

    return face_list


<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    顔認識タスク</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    q1 :        [i] 顔認識する画像を保存する Queue</span>
<span class="auto-style2">    q2 :        [o] 顔認識した結果を保存する Queue</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    無し</span>
<span class="auto-style2">'''</span>
<span class="auto-style2"># def DetectFacesProcess(cascade, q1, q2):</span>
<span class="auto-style2">def DetectFacesProcess(q1, q2):</span>
<span class="auto-style2">    while True:</span>
<span class="auto-style2">        try:</span>
<span class="auto-style2">            image = q1.get(True, 10)</span>

<span class="auto-style2">            # 終了処理： q1.get から取得したものが int で -1 なら終了</span>
<span class="auto-style2">            if type(image) == int:</span>
<span class="auto-style2">                if image == -1:</span>
<span class="auto-style2">                    break</span>

<span class="auto-style2">            # 顔認識</span>
<span class="auto-style2">            face_list = DetectFaces(cascade, image)</span>

<span class="auto-style2">            q2.put(face_list)</span>
<span class="auto-style2">        except Empty: # timeout of q1.get()</span>
<span class="auto-style2">            print("Timeout happen.")</span>

<span class="auto-style2">    print("Finish DetectFacesProcess()")    </span>


'''
[Abstract]
    検出された顔枠情報リストを使って、image 上に赤枠を描画する。
[Param]
    image :         OpenCV 形式の画像
    face_list :     検出された顔枠情報リスト
[Return]
    無し
'''
def DrawFaceRectangles(image, face_list):
    # 検出した顔の数だけ赤枠を描画
    if len(face_list) != 0:
        for (pos_x, pos_y, w, h) in face_list:
            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")
            cv2.rectangle(frame, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)


'''
[Abstract]
    main 関数 
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15") 

    #
    windowInitialized = False

<span class="auto-style2">    q1 = mp.Queue()</span>
<span class="auto-style2">    q2 = mp.Queue()</span>

<span class="auto-style2">    # "cannot pickle object" というエラーが出て解決できなかったので、args に cascade を加えるのを断念</span>
<span class="auto-style2">    # 合わせて cascade をグローバル変数に。悔しい。</span>
<span class="auto-style2">    p = mp.Process(target=DetectFacesProcess, args=(q1, q2))</span>
<span class="auto-style2">    # p = mp.Process(target=DetectFacesProcess, args=(cascade, q1, q2))</span>
<span class="auto-style2">    p.daemon = True</span>
<span class="auto-style2">    p.start()</span>

    init = False

    while(True):
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # 顔認識</span>
<span class="auto-style2">                if (q1.qsize() &lt;= 1) and (q2.qsize() &lt;= 1):</span>
<span class="auto-style2">                    q1.put(frame)</span>

<span class="auto-style2">                if q2.qsize() != 0:</span>
<span class="auto-style2">                    face_list = q2.get()</span>
<span class="auto-style2">                    init = True</span>

<span class="auto-style2">                if init == True:</span>
<span class="auto-style2">                    # 検出した顔枠を描画</span>
<span class="auto-style2">                    DrawFaceRectangles(frame, face_list)</span>

                # PC画面サイズに合わせて適当にリサイズ後、表示
                frame2 = cv2.resize(frame, (1280, 760))
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # ウィンドウ表示位置が安定しないので、最初の起動時のみ表示場所を指定
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # "z" キーを押されていたら終了
            k = cv2.waitKey(1)      # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！
            if k == ord("z"):
                break
            
            # 指定ウィンドウが無かったら終了
            if not IsWindowVisible(winname):
                break


        except KeyboardInterrupt:
            print("KeyboardInterrupt")
            break

<span class="auto-style2">    # Terminate process p</span>
<span class="auto-style2">    q1.put(-1)</span>
<span class="auto-style2">    # Waiting for process p to finish</span>
<span class="auto-style2">    p.join()</span>

    print("Finish main()")
    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>結果：</p>
  <p>期待する動作をしてくれるようになりました。</p>
  <p>プロセス起動の引数として cascade を一緒に渡したかったのですが、"cannot pickle object" 
  というエラーを発生して実現できませんでした。残念ながら cascade をグローバル変数へ変更することで問題を回避しています。<br>対応策がわかったら記事をアップデートしたいと思います。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
	<video controls autoplay="y" loop="y" src="connect_with_mjpeg/mjpeg_opencv.mp4" width="800px">
	  <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
	</video>

  <p>[動画] OpenCV で顔認識してみた様子</p>
  
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
</section>


<section>
  <h2><a name="ライセンス">ライセンス</a></h2>
<p>本ページの情報は、特記無い限り下記 MIT ライセンスで提供されます。</p>
<table class="border-collapse" style="width: 600px; background-color: #F0F0F0; word-break: break-word;">
  <tr>
    <td>
MIT License<br><br>

Copyright (c) 2022  Kinoshita Hidetoshi<br><br>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:<br><br>

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.<br><br>

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
    </td>
  </tr>
</table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
	<h2><a name="参考">参考</a></h2>
	<ul>
		<li>[1] ネットワークカメラCGIコマンドインターフェース仕様書　統合版<br>
        <a href="https://sol.panasonic.biz/security/cgi-bin/ipro/download/tbookmarka_m.cgi?m=%20&amp;mm=2012100910461872" target="_blank">https://sol.panasonic.biz/security/cgi-bin/ipro/download/tbookmarka_m.cgi?m=%20&amp;mm=2012100910461872</a></li>
        <li>[2] python - example - stream mjpeg - Code Examples 
        (code-examples.net)<br>
        <a href="https://code-examples.net/en/q/14b274d" target="_blank">
        https://code-examples.net/en/q/14b274d</a></li>
	</ul>
</section>

<p>&nbsp;</p>
<p>&nbsp;</p>

<hr>

<p>&nbsp;</p>

<section>
	<h2 style="margin-bottom:5px">記載</h2>
	<table>
	  <tr>
	    <td class="td_history_date">2022-04-17</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">ライセンスを追加</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">2022-04-16</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">新規作成 </td>
	  </tr>
	</table>
</section>

<p>&nbsp;</p>

<footer>
	<p><small>&copy; copyright 2022 木下英俊</small></p>
</footer>

</body>
</html>
