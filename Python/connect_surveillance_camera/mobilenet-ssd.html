<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="kinoshita hidetoshi (木下 英俊)">
  <meta name="description" content="木下英俊が自身のためにプログラムメモを残すことを目的に作成したページです。">
  <meta name="keywords" content="">
  <!-- キャッシュ無効化 -->
  <meta http-equiv="Cache-Control" content="no-cache">
	
  <!-- タイトル -->
  <title>物体検知 － MobileNet-SSD | Programing Items</title>
	
  <!-- ファビコン -->
  <link rel="shortcut icon" href="../../favicon.ico">
  
  <!-- CSS -->
  <link href="https://unpkg.com/ress/dist/ress.min.css" rel="stylesheet">
	<link rel="stylesheet" href="../../design.css" type="text/css">
  
	<!-- Start for 'google-code-prettify' -->
	<link href="../../prettify/styles/desert.css" rel="stylesheet" type="text/css">
	<script src="../../prettify/prettify.js" type="text/javascript"></script>
	<!-- End for 'google-code-prettify' -->	
	
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2DZQK54C2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-V2DZQK54C2');
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->

  <style type="text/css">
  .auto-style1 {
    background-color: #505000;
  }
  .auto-style2 {
  text-decoration: underline;
}
  .auto-style3 {
  color: #FF0000;
}
  .auto-style4 {
	background-color: #FFFF00;
  }
  .auto-style5 {
	color: #FF0000;
	background-color: #FFFF00;
  }
  </style>

</head>

<body onload="prettyPrint();">
	
<h1>物体検知 － MobileNet-SSD</h1>

<p> i-PRO の監視カメラ i-PRO mini (WV-S7130W) と接続してPCで MobileNetV1-SSD, 
MobileNetV2-SSD-Lite を動かしてみます。</p>
<p> &nbsp;</p>

<p>&nbsp;</p>
<table style="border: 1px solid #808080; width: 800px; max-width: 100%; background-color: #F0F0F0;">
  <tr>
    <td>
      <nav>
        <h2>目次</h2>
        <p><a href="#1._準備">1. 準備</a></p>
        <p>&nbsp;&nbsp; <a href="#1-1._Pytorch_をインストールする">1-1. PyTorch をインストールする</a></p>
        <p>&nbsp;&nbsp; <a href="#1-2._必要なライブラリをインストール">1-2. 必要なライブラリをインストールする</a></p>
        <p><a href="#2._MobileNetV1-SSD_を動かす（PC 内蔵カメラ）">2. MobileNetV1-SSD を動かす（PC 内蔵カメラ）</a></p>
        <p><a href="#3._MobileNetV1-SSD_を動かす（i-PRO_カメラ）">3. MobileNetV1-SSD を動かす（i-PRO カメラ）</a></p>
        <p><a href="#4._MobileNetV2-SSD_を動かす（PC_内蔵カメラ）">4. MobileNetV2-SSD-Lite を動かす（PC 内蔵カメラ）</a></p>
        <p><a href="#5._MobileNetV2-SSD_を動かす（i-PRO_カメラ）">5. MobileNetV2-SSD-Lite を動かす（i-PRO カメラ）</a></p>
        <br>
        <p><a href="#ライセンス">ライセンス</a></p>
        <p><a href="#参考">参考</a></p>
      </nav>
    </td>
  </tr>
</table>
<p>&nbsp;</p>

<section>
<p> 製品紹介ページ： </p>
<ul>
  <li><a href="https://cwc.i-pro.com/pages/i-pro-mini-lp" target="_blank">
  i-pro-mini-lp</a></li>
  <li>
  <a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130wux" target="_blank">
  i-PRO mini 無線LANモデル WV-S7130WUX</a></li>
</ul>
<p> &nbsp;</p>
<p><img alt="i-PRO mini" src="mobilenet-ssd/img10.jpg" class="border_with_drop-shadow" width="400"></p>
<p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
	<h2> <a name="1._準備">1. 準備</a></h2>
	<h4>[概要]</h4>
    <p>Python を事前にインストール済みであることを前提に記載します。</p>
    <p>私の評価環境は以下の通りです。</p>
  <p>&nbsp;</p>
	
	<h4>[評価環境]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	<p> &nbsp;</p>
    <h3> <a name="1-1._Pytorch_をインストールする">1-1. Pytorch をインストールする</a></h3>
    <p> (1)</p>
    <p> 下記URLを開きます。</p>
    <p> <a href="https://pytorch.org/get-started/locally/" target="_blank">
    https://pytorch.org/get-started/locally/</a></p>
    <p> &nbsp;</p>
    <p> (2)</p>
    <p> 下図のような画面を表示するので、使用される環境を選択します。</p>
    <p> 私は Windows 環境で多くの人が動作する例を作成したいので、Computer Platform として CPU を選択してみました。<br>
    Package はなんとなく&nbsp;Pip を選択してみます。</p>
    <p> commandは <span class="cpp-source">pip3 install torch torchvision torchaudio</span> となりました。</p>
    <p><img alt="PyTorch ホームページ画面１" class="border_with_drop-shadow" src="mobilenet-ssd/img6.jpg" width="800"></p>
    <p><a href="mobilenet-ssd/img5.jpg" target="_blank">
    <img alt="PyTorch ホームページ画面２" class="border_with_drop-shadow" src="mobilenet-ssd/img5.jpg" width="800"></a></p>
    <p> &nbsp;</p>
    <p> ちなみに "CUDA 11.3" を選択すると <span class="cpp-source">pip3 install torch 
    torchvision torchaudio --extra-index-url 
    https://download.pytorch.org/whl/cu113</span> となりました。</p>
    <p> &nbsp;</p>
    <p> (3)</p>
    <p> 表示されたコマンドをコマンドプロンプトなどのターミナルから入力することで Pytorch をインストールします。</p>
    <p> &nbsp;</p>
    <p> <a href="image_classification_vgg/img7.gif" target="_blank">
    <img alt="PyTorch インストール画面１" class="border_with_drop-shadow" src="mobilenet-ssd/img7.gif" width="800"></a></p>
    <p> &nbsp;</p>
    <p> <a href="image_classification_vgg/img9.jpg" target="_blank">
    <img alt="PyTorch インストール画面２" class="border_with_drop-shadow" src="mobilenet-ssd/img9.jpg" width="800"></a></p>
    <p> &nbsp;</p>
    <p> <a href="image_classification_vgg/imgD.gif" target="_blank">
    <img alt="PyTorch インストール画面３" class="border_with_drop-shadow" src="mobilenet-ssd/imgD.gif" width="800"></a></p>
    <p> &nbsp;</p>
    <p> これで Pytorch のインストールを完了です。</p>
    <p> &nbsp;</p>
    <p> &nbsp;</p>
    <h3> <a name="1-2._必要なライブラリをインストール">1-2. 必要なライブラリをインストール</a></h3>
    <p> opencv を使用するので、下記コマンドによりインストールします。</p>
    <p> <span class="cpp-source">pip install opencv-python </span></p>
    <p> &nbsp;</p>
    <p> &nbsp;</p>
	
</section>
	
<p>&nbsp;</p>

<section>
	<h2> <a name="2._MobileNetV1-SSD_を動かす（PC 内蔵カメラ）">2. MobileNetV1-SSD を動かす（PC 内蔵カメラ）</a></h2>
	<h4>[概要]</h4>
    <p>MobileNetV1-SSD を PyTorch の環境で動かしてみます。</p>
    <p><a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> というこの内容そのままのものが GitHub で公開されていました。これを取得して動作させてみます。</p>
	<p>ちなみに pytorch-ssd のライセンスは "MIT License" です。</p>
    <p><a href="mobilenet-ssd/imgC.jpg" target="_blank">
    <img alt="pytorch-ssd ホームページ画面" class="border_with_drop-shadow" src="mobilenet-ssd/imgC.jpg" width="800"></a></p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
  <h4>[評価環境]</h4>
  <table>
  <tbody>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>&nbsp;</td>
      <td>PyTorch,</td>
      <td>1.11.0</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </tbody>
</table>

  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h4>[手順]</h4>
    <p>1. <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> から git clone してソースコード一式を入手します。</p>
    <p>（git を既にインストール済みとして記載します。）</p>
    <pre>git clone https://github.com/qfgaohao/pytorch-ssd.git</pre>
    <p>&nbsp;</p>
    <p>2. README.md 中の "Run the live MobilenetV1 SSD demo" に記載の内容に従って下記を実行します。</p>
    <p>最初の２行は学習済みデータとラベルデータの取得なので、初めて実行するときのみ実施すれば良いです。</p>
    <pre>wget -P models https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth 
wget -P models https://storage.googleapis.com/models-hao/voc-model-labels.txt
python run_ssd_live_demo.py mb1-ssd models/mobilenet-v1-ssd-mp-0_675.pth models/voc-model-labels.txt </pre>
    <p>&nbsp;</p>
    <p>ところで Windows に標準では wget コマンドは無いので、上記を実行してもエラーになります。Windows 用の wget を入手して使っても良いですが、代わりに 
    bitsadmin コマンドで代用するという方法もあります。</p>
    <p>&nbsp;</p>
    <p class="auto-style2"><strong>bitsadmin.exe</strong> の書き方：</p>
    
    <blockquote>
      <strong>bitsadmin.exe</strong> /transfer ＜ジョブ名＞ ＜URL＞ ＜保存先ファイル名（フルパス）＞</blockquote>
    
    <p>上記内容を bitsadmin.exe で置き換えると以下のようになるので、Windows 環境の方はこちらで実施してもOKです。<br>
    <span class="auto-style3">{作業フォルダ}</span> の部分をご自身の環境に合わせて修正して実行してください。</p>
    <pre>bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth c:\<span class="auto-style3">{作業フォルダ}</span>\models\mobilenet-v1-ssd-mp-0_675.pth
bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/voc-model-labels.txt c:\<span class="auto-style3">{作業フォルダ}</span>\models\voc-model-labels.txt
python run_ssd_live_demo.py mb1-ssd models/mobilenet-v1-ssd-mp-0_675.pth models/voc-model-labels.txt</pre>
    <p>&nbsp;</p>
    <p>3. 上記手順でプログラム（"python run_ssd_live_demo.py ･･･" のところ）を実行したところ、私の環境では下図のようなエラーを表示して正常に動作しませんでした。</p>
    <p><a href="mobilenet-ssd/img9.gif" target="_blank">
    <img alt="pytorch-ssd － run_ssd_live_demo.py エラー発生時の画面" src="mobilenet-ssd/img9.gif" width="800"></a></p>
    <p>&nbsp;</p>
    <p>どうやら、box[0], box[1], box[2], box[3] 
    が浮動小数点なのですがここの引数は整数(int)である必要がある、ということがエラーの理由のようです。<br>エラーとなった 76行目と、同様に 
    79行目の２カ所を int 型へ変換するように修正します。下図だと4行目、7行目の色付きの場所へ int() を追加しました。<br>
    これでエラーを解決してプログラムを実行できるようになりました。</p>
    <pre class="prettyprint linenums:73 lang-py">
        for i in range(boxes.size(0)):
        box = boxes[i, :]
        label = f"{class_names[labels[i]]}: {probs[i]:.2f}"
        cv2.rectangle(orig_image, (<span class="auto-style1">int(</span>box[0]<span class="auto-style1">)</span>, <span class="auto-style1">int(</span>box[1]<span class="auto-style1">)</span>), (<span class="auto-style1">int(</span>box[2]<span class="auto-style1">)</span>, <span class="auto-style1">int(</span>box[3]<span class="auto-style1">)</span>), (255, 255, 0), 4)

        cv2.putText(orig_image, label,
                    (<span class="auto-style1">int(</span>box[0]<span class="auto-style1">)</span>+20, <span class="auto-style1">int(</span>box[1]<span class="auto-style1">)</span>+40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,  # font scale
                    (255, 0, 255),
                    2)  # line type</pre>
    <p>修正を <a href="https://github.com/qfgaohao/pytorch-ssd/pull/178" target="_blank">Pull Request #178</a> しておきましたが、ポスト後に確認したら私を含めて３件の同件修正が Pull Request 
    されていました。こちらのリポジトリはメンテを終了してそうです。</p>
	<p>&nbsp;</p>
    
    <div class="status_ok" style="width: 700px">
      <div></div>
      <div>
        <p>(2022-08-03 追記)</p>
		<p>私から出した Pull Request (#178) が先ほどマージされました。</p>
		<p>このためマージ後のソースを取得（git clone）した方はこちら 3 に記載の修正は不要です。</p>
        <p>
		<a href="https://github.com/qfgaohao/pytorch-ssd/pull/178" target="_blank">Bug fix. 
		by kinoshita-hidetoshi · Pull Request #178 · qfgaohao/pytorch-ssd · 
		GitHub</a></p>
      </div>
    </div>

      <p>&nbsp;</p>
	  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>4. 修正したプログラムを動かした様子を以下に示します。</p>
    <p>カメラはPC内蔵のカメラです。PyTorch は前述の通り CPU 版ですがかなり快適に動作できています。</p>
    <p>&nbsp;</p>
    
  	<p>[動画] プログラムを動作させた様子（PC 内蔵カメラ）</p>
    <video controls muted autoplay="y" loop="y" src="mobilenet-ssd/mobilenetv1-ssd-pccam.mp4" width="800">
      <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
    </video> <br>
    
	<p>&nbsp;</p>
	<p>&nbsp;</p>
  
    <div class="status_information">
      <div></div>
      <div>
        <p><strong>NOTE</strong></p>
        <p>プログラム "run_ssd_live_demo.py" 中で PC内蔵カメラ からのキャプチャーを行っている部分は下記の箇所です。</p>
		    <p><span class="cpp-source">cap = cv2.VideoCapture(0)   # capture from camera</span></p>
		  </div>
    </div>

    <p>&nbsp;</p>
	<p>&nbsp;</p>
  <p>&nbsp;</p>
    
</section>
	
<p>&nbsp;</p>

<section>
	<h2><a name="3._MobileNetV1-SSD_を動かす（i-PRO_カメラ）">3. MobileNetV1-SSD を動かす（i-PRO カメラ）</a></h2>
	<h4>[概要]</h4>
    <p>MobileNetV1-SSD を PyTorch の環境で動かしてみます。</p>
	<p>本章では i-PRO カメラとPCを LAN 接続してリアルタイムで物体検知してみます。前章と同様に <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> を使って行います。</p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
  <h4>[評価環境]</h4>
  <table>
  <tbody>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>&nbsp;</td>
      <td>PyTorch,</td>
      <td>1.11.0</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </tbody>
</table>

  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h4>[手順]</h4>
    <p>1. <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> から git clone してソースコード一式を入手します。（前章と同じです。実施済みなら不要です。）</p>
    <pre>git clone https://github.com/qfgaohao/pytorch-ssd.git</pre>
    <p>&nbsp;</p>
    <p>2. README.md 中の "Run the live MobilenetV1 SSD demo" に記載の内容に従って下記を実行します。（前章と同じです。実施済みなら不要です。）</p>
    <pre>wget -P models https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth 
wget -P models https://storage.googleapis.com/models-hao/voc-model-labels.txt
</pre>
    <p>&nbsp;</p>
    <p>Windows 環境で bitsadmin.exe を使って実施する場合は下記を実施します。<br>
    <span class="auto-style3">{作業フォルダ}</span> の部分をご自身の環境に合わせて修正して実行してください。</p>
    <pre>bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth c:\<span class="auto-style3">{作業フォルダ}</span>\models\mobilenet-v1-ssd-mp-0_675.pth
bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/voc-model-labels.txt c:\<span class="auto-style3">{作業フォルダ}</span>\models\voc-model-labels.txt
</pre>
    <p>&nbsp;</p>
	<p>3. 下記コマンドを入力してプログラムを起動します。ここでは４番目の引数として RTSP 表記で i-PRO カメラの接続を記載します。</p>
	<p><span class="auto-style3">{user-id}</span>, <span class="auto-style3">
	{password}</span>, <span class="auto-style3">{ip-address}</span> 
	の部分をご自身が使われる i-PRO カメラの設定に合わせて修正して実行してください。</p>
	<p>その他 RTSP に関しては記事「<a href="connect_with_rtsp.html">RTSP で画像を取得する</a>」を参照ください。</p>
    <pre>python run_ssd_live_demo.py mb1-ssd models/mobilenet-v1-ssd-mp-0_675.pth models/voc-model-labels.txt <span class="auto-style4">rtsp://</span><span class="auto-style5">{user-id}</span>:<span class="auto-style5">{password}</span>@<span class="auto-style5">{ip-address}</span><span class="auto-style4">/MediaInput/stream_1</span></pre>
    <p>(例) <span class="cpp-source">python run_ssd_live_demo.py mb1-ssd 
	models/mobilenet-v1-ssd-mp-0_675.pth models/voc-model-labels.txt 
	rtsp://admin:Admin12345@192.168.0.10/MediaInput/stream_1</span></p>
	  <p>&nbsp;</p>
    <p>&nbsp;</p>
	<p>4. プログラムを動かした様子を以下に示します。</p>
	<p>PyTorch は前述の通り CPU 版ですがかなり快適に動作できています。</p>
	<p>i-PRO カメラの設定を 10fps にしています。私のノートPC環境では 30fps 
	動作させると映像が少しずつ遅延していきました。AI処理なしに映像表示させると 30fps 
	表示できているので、AI処理に伴うCPU負荷に原因するものと分析します。GPU無しの環境、CPU 版での動作で Full-HD 画像を 10fps 
	でAI処理できているのですから、私個人の見解ですが、 MobileNet は十分に軽量で高性能な AI だと考えます。</p>
    <p>&nbsp;</p>
    
  	<p>[動画] プログラムを動作させた様子 １（i-PRO カメラ）</p>
    <video controls muted autoplay="y" loop="y" src="mobilenet-ssd/movilenetv1-ssd-ipromini_1.mp4" width="800">
      <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
    </video>
    
  	<p>&nbsp;</p>
	<p>[動画] プログラムを動作させた様子 ２ － 「<a href="https://pixabay.com/ja/videos/人-商業-店-忙しい-モール-6387/" target="_blank">人 
  商業 店 - Free video on Pixabay</a>」の例（i-PRO カメラ）</p>
  <p>入力画像として、 <a href="https://pixabay.com/" target="_blank">
  https://pixabay.com</a> から取得した下記動画をテストに使用させていただきました。商用利用無料、帰属表示必要なし、のコンテンツです。</p>
  <p>PC上で再生表示する動画を i-PRO カメラで接写しているため、画質が荒いこと、認識精度が微妙なこと、はご容赦ください。</p>

    <p>
	こちらの例の場合、人が一定より小さいと認識できないようでした。カメラをディスプレに近づけて人のサイズを大きくすることで、AIが人を認識できるようになりました。</p>
	<p>別ページ紹介の「<a href="connect_to_wv-xae200w.html">機能拡張ソフトウェア(WV-XAE200W)</a>」でも同じ映像を使って評価していますが、こちらの評価では同じ映像で小さい人を認識できています。この比較からも専用商品である 
	WV-XAE200WUX の画像認識性能の高さを再確認させていただきました。</p>
    <video controls muted autoplay="y" loop="y" src="mobilenet-ssd/movilenetv1-ssd-ipromini_2.mp4" width="800">
      <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
    </video>

    <p>&nbsp;</p>
	<p>&nbsp;</p>
	<p>以上です。というわけで、プログラムを１行も書くことなく i-PRO カメラとPCを接続して MobileNetV1-SSD 
	を実行することができました。</p>
	<p>&nbsp;</p>
  
    <div class="status_information">
      <div></div>
      <div>
        <p><strong>NOTE</strong></p>
        <p>プログラム "run_ssd_live_demo.py" 中で i-PRO カメラからのキャプチャーを行っている部分は下記の箇所です。</p>
		    <p><span class="cpp-source">cap = cv2.VideoCapture(sys.argv[4])  # capture from file</span></p>
		  </div>
    </div>

    <p>&nbsp;</p>
    <p>&nbsp;</p>
    
</section>
	
<p>&nbsp;</p>

<section>
	<h2> <a name="4._MobileNetV2-SSD_を動かす（PC_内蔵カメラ）">4. MobileNetV2-SSD を動かす（PC 内蔵カメラ）</a></h2>
	<h4>[概要]</h4>
    <p>MobileNetV2-SSD を PyTorch の環境で動かしてみます。</p>
    <p>MobileNetV1-SSD 同様に <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> に含まれていますので、これを取得して動作させてみます。</p>
    <p><a href="mobilenet-ssd/imgC.jpg" target="_blank">
    <img alt="pytorch-ssd ホームページ画面" class="border_with_drop-shadow" src="mobilenet-ssd/imgC.jpg" width="800"></a></p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
  <h4>[評価環境]</h4>
  <table>
  <tbody>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>&nbsp;</td>
      <td>PyTorch,</td>
      <td>1.11.0</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </tbody>
</table>

  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h4>[手順]</h4>
    <p>1. <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> から git clone してソースコード一式を入手します。（前章と同じです。実施済みなら不要です。）</p>
    <pre>git clone https://github.com/qfgaohao/pytorch-ssd.git</pre>
    <p>&nbsp;</p>
    <p>2. README.md 中の "Run the live MobileNetV2 SSD Lite demo" に記載の内容に従って下記を実行します。</p>
    <p>最初の２行は学習済みデータとラベルデータの取得なので、初めて実行するときのみ実施すれば良いです。また２行目の 
	"voc-model-labels.txt" は MobileNetV1-SSD と同一のファイルです。</p>
    <pre>
wget -P models https://storage.googleapis.com/models-hao/mb2-ssd-lite-mp-0_686.pth
wget -P models https://storage.googleapis.com/models-hao/voc-model-labels.txt
python run_ssd_live_demo.py mb2-ssd-lite models/mb2-ssd-lite-mp-0_686.pth models/voc-model-labels.txt</pre>
    <p>&nbsp;</p>
    
    <p>上記内容を bitsadmin.exe で置き換えると以下のようになるので、Windows 環境の方はこちらで実施してもOKです。<br>
    <span class="auto-style3">{作業フォルダ}</span> の部分をご自身の環境に合わせて修正して実行してください。</p>
    <pre>bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/mb2-ssd-lite-mp-0_686.pth c:\<span class="auto-style3">{作業フォルダ}</span>\models\mb2-ssd-lite-mp-0_686.pth
bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/voc-model-labels.txt c:\<span class="auto-style3">{作業フォルダ}</span>\models\voc-model-labels.txt
python run_ssd_live_demo.py mb2-ssd-lite models/mb2-ssd-lite-mp-0_686.pth models/voc-model-labels.txt</pre>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>3. プログラムを動かした様子を以下に示します。</p>
    <p>カメラはPC内蔵のカメラです。PyTorch は前述の通り CPU 版ですがかなり快適に動作できています。</p>
    <p>&nbsp;</p>
    
  	<p>[動画] プログラムを動作させた様子（PC 内蔵カメラ）</p>
    <video controls muted autoplay="y" loop="y" src="mobilenet-ssd/mobilenetv2-ssd-pccam.mp4" width="800">
      <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
    </video> <br>
    
	<p>&nbsp;</p>
	<p>MobiletNetV2-ssd-lite で動作させているのは正しいですが、こちら映像を見るだけでは V1, V2 の違いはわからないですね。</p>
	<p>私が触ってみた印象ですが、認識精度が若干向上して CPU 負荷も若干軽くなったという気がします。</p>
	<p>&nbsp;</p>
  
  <p>&nbsp;</p>
    
</section>
	
<p>&nbsp;</p>

<section>
	<h2><a name="5._MobileNetV2-SSD_を動かす（i-PRO_カメラ）">5. MobileNetV2-SSD を動かす（i-PRO カメラ）</a></h2>
	<h4>[概要]</h4>
    <p>MobileNetV2-SSD を PyTorch の環境で動かしてみます。</p>
	<p>本章では i-PRO カメラとPCを LAN 接続してリアルタイムで物体検知してみます。前章と同様に <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> を使って行います。</p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
  <h4>[評価環境]</h4>
  <table>
  <tbody>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>&nbsp;</td>
      <td>PyTorch,</td>
      <td>1.11.0</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>

    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>

    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </tbody>
</table>

  <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h4>[手順]</h4>
    <p>1. <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
    pytorch-ssd</a> から git clone してソースコード一式を入手します。（前章と同じです。実施済みなら不要です。）</p>
    <pre>git clone https://github.com/qfgaohao/pytorch-ssd.git</pre>
    <p>&nbsp;</p>
    
    <p>2. README.md 中の "Run the live MobilenetV1 SSD demo" に記載の内容に従って下記を実行します。（前章と同じです。実施済みなら不要です。）</p>
    <pre>wget -P models https://storage.googleapis.com/models-hao/mb2-ssd-lite-mp-0_686.pth
wget -P models https://storage.googleapis.com/models-hao/voc-model-labels.txt</pre>
    <p>&nbsp;</p>
    <p>Windows 環境で bitsadmin.exe を使って実施する場合は下記を実施します。<br>
    <span class="auto-style3">{作業フォルダ}</span> の部分をご自身の環境に合わせて修正して実行してください。</p>
    <pre>bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/mb2-ssd-lite-mp-0_686.pth c:\<span class="auto-style3">{作業フォルダ}</span>\models\mb2-ssd-lite-mp-0_686.pth
bitsadmin /TRANSFER htmldl https://storage.googleapis.com/models-hao/voc-model-labels.txt c:\<span class="auto-style3">{作業フォルダ}</span>\models\voc-model-labels.txt</pre>
    <p>&nbsp;</p>
    
	<p>3. 下記コマンドを入力してプログラムを起動します。ここでは４番目の引数として RTSP 表記で i-PRO カメラの接続を記載します。</p>
	<p><span class="auto-style3">{user-id}</span>, <span class="auto-style3">
	{password}</span>, <span class="auto-style3">{ip-address}</span> 
	の部分をご自身が使われる i-PRO カメラの設定に合わせて修正して実行してください。</p>
	<p>その他 RTSP に関しては記事「<a href="connect_with_rtsp.html">RTSP で画像を取得する</a>」を参照ください。</p>
    <pre>python run_ssd_live_demo.py mb2-ssd-lite models/mb2-ssd-lite-mp-0_686.pth models/voc-model-labels.txt <span class="auto-style4">rtsp://</span><span class="auto-style5">{user-id}</span>:<span class="auto-style5">{password}</span>@<span class="auto-style5">{ip-address}</span><span class="auto-style4">/MediaInput/stream_1</span></pre>
    <p>(例) <span class="cpp-source">python run_ssd_live_demo.py mb2-ssd-lite models/mb2-ssd-lite-mp-0_686.pth models/voc-model-labels.txt 
	rtsp://admin:Admin12345@192.168.0.10/MediaInput/stream_1</span></p>
	  <p>&nbsp;</p>
    <p>&nbsp;</p>
    
	<p>4. プログラムを動かした様子を以下に示します。</p>
	<p>PyTorch は前述の通り CPU 版ですがかなり快適に動作できています。</p>
	<p>i-PRO カメラの設定を 10fps にしています。私のノートPC環境では 30fps 
	動作させると映像が少しずつ遅延していきました。AI処理なしに映像表示させると 30fps 
	表示できているので、AI処理に伴うCPU負荷に原因するものと分析します。GPU無しの環境、CPU 版での動作で Full-HD 画像を 10fps 
	でAI処理できているのですから、私個人の見解ですが、 MobileNet は十分に軽量で高性能な AI だと考えます。</p>
    <p>&nbsp;</p>
    
  	<p>[動画] プログラムを動作させた様子（i-PRO カメラ）</p>
    <video controls muted autoplay="y" loop="y" src="mobilenet-ssd/movilenetv2-ssd-ipromini_1.mp4" width="800">
      <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
    </video>
    
  	<p>&nbsp;</p>
	<p>MobiletNetV2-ssd-lite で動作させているのは正しいですが、こちら映像を見るだけでは V1, V2 の違いはわからないですね。</p>
	<p>私が触ってみた印象ですが、認識精度が若干向上して CPU 負荷も若干軽くなったという気がします。</p>
	<p>&nbsp;</p>
	&nbsp;<p>以上です。というわけで、プログラムを１行も書くことなく i-PRO カメラとPCを接続して MobileNetV2-SSD 
	も実行することができました。</p>
	<p>&nbsp;</p>
  
    <p>&nbsp;</p>
    
</section>
	
<p>&nbsp;</p>

<section>
  <h2><a name="ライセンス">ライセンス</a></h2>
<p>本ページの情報は、特記無い限り下記 MIT ライセンスで提供されます。</p>
<table class="border-collapse" style="width: 600px; background-color: #F0F0F0; word-break: break-word;">
  <tr>
    <td>
The MIT License (MIT)<br><br>

Copyright © 2022 Kinoshita Hidetoshi<br><br>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:<br><br>

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.<br><br>

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
    </td>
  </tr>
</table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<br>

<section>
	<h2><a name="参考">参考</a></h2>
	<ul>
		<li>[1] PyTorch<br><a href="https://pytorch.org/" target="_blank">
      https://pytorch.org/</a></li>
    <li>[2] qfgaohao/pytorch-ssd: MobileNetV1, MobileNetV2, VGG based 
      SSD/SSD-lite implementation in Pytorch 1.0 / Pytorch 0.4. Out-of-box 
      support for retraining on Open Images dataset. ONNX and Caffe2 support. 
      Experiment Ideas like CoordConv. (github.com)<br>
      <a href="https://github.com/qfgaohao/pytorch-ssd" target="_blank">
      https://github.com/qfgaohao/pytorch-ssd</a></li>
    <li>[3] PyTorchでMobileNet SSDによるリアルタイム物体検出｜はやぶさの技術ノート (cpp-learning.com)<br>
      <a href="https://cpp-learning.com/pytorch_mobilenet-ssd/" target="_blank">
      https://cpp-learning.com/pytorch_mobilenet-ssd/</a></li>
    <li>[4] MobilenetSSD : 高速に物体検出を行う機械学習モデル. ailia… | by Kazuki Kyakuno | axinc | Medium<br>
      <a href="https://medium.com/axinc/mobilenetssd-高速に物体検出を行う機械学習モデル-be3ca37c411" target="_blank">
      https://medium.com/axinc/mobilenetssd-高速に物体検出を行う機械学習モデル-be3ca37c411</a></li>
		<li>[5] Everything You Need To Know About Torchvision’s SSDlite Implementation | PyTorch<br>
      <a href="https://pytorch.org/blog/torchvision-ssdlite-implementation/" target="_blank">
      https://pytorch.org/blog/torchvision-ssdlite-implementation/</a></li>
		<li>[6] vision/ssdlite.py at b6f733046c9259f354d060cd808241a558d7d596 · pytorch/vision · GitHub<br>
  		<a href="https://github.com/pytorch/vision/blob/b6f733046c9259f354d060cd808241a558d7d596/torchvision/models/detection/ssdlite.py#L159-L162" target="_blank">
	  	https://github.com/pytorch/vision/blob/b6f733046c9259f354d060cd808241a558d7d596/torchvision/models/detection/ssdlite.py#L159-L162</a></li>
		<li>[7] Models and pre-trained weights — Torchvision main documentation (pytorch.org)<br>
		  <a href="https://pytorch.org/vision/main/models.html" target="_blank">
		  https://pytorch.org/vision/main/models.html</a></li>
		<li>[8] Visualization utilities — Torchvision 0.11.0 documentation (pytorch.org)<br>
      <a href="https://pytorch.org/vision/0.11/auto_examples/plot_visualization_utils.html" target="_blank">
      https://pytorch.org/vision/0.11/auto_examples/plot_visualization_utils.html</a></li>
		<li>[9] PyTorchでObeject Detection (mashykom.com)<br>
      <a href="https://www.koi.mashykom.com/pytorch2.html" target="_blank">
      https://www.koi.mashykom.com/pytorch2.html</a></li>
	</ul>
</section>

<p>&nbsp;</p>

<hr>

<p>&nbsp;</p>

<section>
	<h2 style="margin-bottom:5px">変更履歴</h2>
	<table>
	  <tr>
	    <td class="td_history_date">2022-08-30</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">「3. MobileNetV1-SSD を動かす（i-PRO カメラ）」を追加</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">&nbsp;</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">「4. MobileNetV2-SSD を動かす（PC 内蔵カメラ）」を追加</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">&nbsp;</td>
	    <td class="td_history_separator">&nbsp;</td>
	    <td class="td_history">「5. MobileNetV2-SSD を動かす（i-PRO カメラ）」を追加</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">2022-08-03</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">"Pull Request #178" がマージされたことを追記</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">2022-06-26</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">新規作成 </td>
	  </tr>
	</table>
</section>

<p>&nbsp;</p>

<section>
<p><a href="../../index.html" target="_parent">Programming Items トップページ</a></p>
<p><a href="../../privacy_policy.html">プライバシーポリシー</a></p>
</section>

<p>&nbsp;</p>

<footer>
	<p><small>Copyright © 2022 Kinoshita Hidetoshi (木下英俊)</small></p>
</footer>

</body>
</html>
